\documentclass[../main.tex]{subfiles}
\begin{document}

Die Vektor Embeddings werden selten alleine betrachtet, sondern als Teil eines Vektorraums.
In diesem Raum wird durch die Embeddings Richtung und Entfernung Bedeutung zugewiesen.
So liegt Text, der ähnliche Semantik hat, nahe aneinander in seiner Embedding Darstellung in diesem Vektorraum.
Außerdem stellt das Verhältnis zwischen zwei Vektoren semantische Konzepte dar und es können \enquote{Konzeptachsen} gebildet werden, die verallgemeinernd Konzepte erfassen, wie in Abbildung \ref{fig:embeddingspace} zu erkennen.
\cite{heimerl2018interactive,mikolov2013efficient}

\begin{figure}[ht]
    \centering
    \includegraphics[scale=.23]{"bilder/embeddingspace.png"}
    \caption{Darstellung von einem ausgedachten Vektor Embedding Raum über zwei Konzeptachsen (Selbst gezeichnet)}
    \label{fig:embeddingspace}
\end{figure}

Um einen Vektor Embedding Raum sinnvoll aufzubauen, ist eine einheitliche Methode zur Embedding Generierung nötig, in der die Bedeutungszuweisung von Richtungen kohärent zwischen den Embeddings ist.
Wie bereits erwähnt, wurden \glspl{LLM} für Textverständnis trainiert und können deshalb genutzt werden, um aus einer Texteingabe ein Ausgabe-Vektor Embedding zu erzeugen.
\cite{zhang2023language}

\end{document}