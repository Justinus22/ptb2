\documentclass[../main.tex]{subfiles}
\begin{document}

Der erste Schritt zum Indexing ist das Einteilen der Codebasis in Abschnitte.
Dies wird hier mit der Tree-Sitter Bibliothek durchgeführt, die das Aufteilen von Code bereitstellt \cite{treesitter}.
Als Nächstes werden aus diesen Codeabschnitten Vektor Embeddings erzeugt und im Index gespeichert.

Zum Erfassen der Funktionstüchtigkeit wird eine Metrik eingeführt.
Es gibt ein im Anhang enthaltendes Testprojekt und folgende zehn Testfragen.
Jede dieser Fragen, die \enquote{Where}-Formulierungen aufweisen, zielt auf einen Codeabschnitt des Projektes ab.
\begin{table}[H]
\begin{center}
\caption{Testfragen für die Suchen im Index des Testprojekts}
\label{tab:testfragen}
\begin{tabular}{| m {0.5cm} | m {0.9\textwidth} | }
 
 \hline
 1. & \enquote{Where is the logger implemented?}\\ 
 \hline
 2. & \enquote{Where are the setting changes for the logger handled?}\\ 
 \hline
 3. & \enquote{Where is the linting configured?}\\ 
 \hline
 4. & \enquote{Where is typescript configured?}\\ 
 \hline
 5. & \enquote{Where are the styles for my app?}\\ 
 \hline
 6. & \enquote{Where is my app created?}\\ 
 \hline
 7. & \enquote{Where do I create the IDs for my web view context?}\\ 
 \hline
 8. & \enquote{Where do I manage the state of my web view panels?}\\ 
 \hline
 9. & \enquote{Where do I configure what commands will be available in my vs code extension?}\\ 
 \hline
 10. & \enquote{Where do I retrieve information about vs code settings?}\\
 \hline 

\end{tabular}
\end{center}
\end{table}
\vspace*{-\baselineskip}

Für einen ersten \ref{test1} wird für das Projekt nach vorgestelltem Verfahren ein Index erstellt, welcher dann mit den Fragen durchsucht wird.
Enthalten die drei besten Ergebnisse, also jene, dessen Embedding am meisten Kosinus-Ähnlichkeit mit dem Embedding der Frage hat, den Textabschnitt, der durch die Frage gemeint ist, wird das Ergebnis als richtig gewertet.
Für richtige Ergebnisse wird die Kosinus-Ähnlichkeit notiert, sonst eine 0.

Alle Ergebnisse wurden mithilfe der gpt-35-turbo \cite{completionmodel} und text-embedding-ada-002 \cite{embeddingmodel} Modelle erzeugt.
Für Completions wurde eine Temperature von 0.2 und ein Top-P-Wert von 0.3 gewählt. Alle anderen Einstellungen blieben unverändert.

\begin{table}[H]
\begin{center}
\caption{Ergebnisse der Index- und Suchtests}
\label{tab:ergebnisse}
\begin{tabular}{| m {1cm} | m {1,3cm} | m {1,3cm} |m {1,3cm} |m {1,3cm} |m {1,3cm} |m {1,3cm} | m {1,3cm} |}
 \hline
 Frage & Test 1\labeltext{Test 1}{test1} & Test 2\labeltext{Test 2}{test2} & Test 3\labeltext{Test 3}{test3} & Test 4\labeltext{Test 4}{test4} & Test 5\labeltext{Test 5}{test5} & Test 6\labeltext{Test 6}{test6} & Test 7\labeltext{Test 7}{test7} \\
 \hline
 1. & 0,7993 &0&0,7993&0,7937&0,8008&0,7925&0,8062\\ 
 \hline
 2. & 0,8172 &0,793&0,8172&0,7956&0,8307&0,8049&0,8229\\ 
 \hline
 3. & 0 &0&0&0&0,8436&0&0\\ 
 \hline
 4. & 0,8036 &0,8039&0,8606&0,8606&0,8556&0,852&0,8428\\ 
 \hline
 5. & 0 &0&0&0&0,8138&0,7576&0,7912\\ 
 \hline
 6. &0,7816 &0,7896&0,777&0,777&0&0,7895&0,7912\\ 
 \hline
 7. & 0 &0&0,8087&0&0,8087&0,7844&0\\ 
 \hline
 8. & 0 &0&0&0&0,8596&0&0,7533\\ 
 \hline
 9. &0,8004 &0&0,854&0,8928&0,8516&0&0\\ 
 \hline
 10. &0,7558 &0,7589&0,8434&0,8336&0,8434&0,8337&0,8227\\
 \hline 

\end{tabular}
\end{center}
\end{table}
\end{document}


